import { useState, useEffect } from 'react';
import { motion } from 'framer-motion';
import { Mic, Wifi, WifiOff } from 'lucide-react';
import { AudioVisualizer } from './components/AudioVisualizer';
import { ConversationPanel, Message } from './components/ConversationPanel';
import { ControlPanel } from './components/ControlPanel';
import { StatsDisplay } from './components/StatsDisplay';
import { StatusIndicator, Status } from './components/StatusIndicator';
import { apiService } from './services/api';
import { audioCaptureService, AudioSource } from './services/audioCapture';
import { wsService } from './services/websocket';

function App() {
  const [isListening, setIsListening] = useState(false);
  const [status, setStatus] = useState<Status>('idle');
  const [statusMessage, setStatusMessage] = useState<string>('');
  const [messages, setMessages] = useState<Message[]>([]);
  const [isConnected, setIsConnected] = useState(false);
  const [audioSource, setAudioSource] = useState<AudioSource>('microphone');
  const [stats, setStats] = useState({
    total_turns: 0,
    total_tokens: 0,
    l1_size: 0,
    l2_size: 0,
    l1_tokens: 0,
    l2_tokens: 0,
  });

  // åˆå§‹åŒ– WebSocket è¿æ¥
  useEffect(() => {
    const initWebSocket = async () => {
      try {
        await wsService.connect();
        setIsConnected(true);
        setStatusMessage('å·²è¿æ¥åˆ°æœåŠ¡å™¨');

        // æ³¨å†Œæ¶ˆæ¯å¤„ç†å™¨
        wsService.on('transcript', (message) => {
          const newMessage: Message = {
            id: Date.now().toString(),
            role: message.role || 'student',
            text: message.text || '',
            timestamp: message.timestamp || new Date().toISOString(),
          };
          setMessages(prev => [...prev, newMessage]);
          setStatus(isListening ? 'listening' : 'idle');
        });

        wsService.on('transcript_partial', (message) => {
          // ä¸­é—´è¯†åˆ«ç»“æœï¼Œæ˜¾ç¤ºåœ¨çŠ¶æ€æ 
          setStatusMessage(`è¯†åˆ«ä¸­: ${message.text}`);
        });

        wsService.on('reply', (message) => {
          const replyMessage: Message = {
            id: Date.now().toString(),
            role: 'system',
            text: message.text || '',
            timestamp: message.timestamp || new Date().toISOString(),
          };
          setMessages(prev => [...prev, replyMessage]);
          setStatus(isListening ? 'listening' : 'idle');
          setStatusMessage('å›å¤å·²ç”Ÿæˆ');
        });

        wsService.on('status', (message) => {
          if (message.status === 'processing') {
            setStatus('processing');
            setStatusMessage('æ­£åœ¨è¯†åˆ«è§’è‰²...');
          } else if (message.status === 'generating') {
            setStatus('generating');
            setStatusMessage('æ­£åœ¨ç”Ÿæˆå›å¤...');
          }
        });

        wsService.on('error', (message) => {
          setStatus('error');
          setStatusMessage(message.message || 'å‘ç”Ÿé”™è¯¯');
          setTimeout(() => {
            setStatus(isListening ? 'listening' : 'idle');
          }, 3000);
        });

      } catch (error) {
        console.error('WebSocket è¿æ¥å¤±è´¥:', error);
        setIsConnected(false);
        setStatusMessage('è¿æ¥å¤±è´¥');
      }
    };

    initWebSocket();

    return () => {
      wsService.disconnect();
    };
  }, []);

  // å®šæœŸæ›´æ–°ç»Ÿè®¡ä¿¡æ¯
  useEffect(() => {
    const interval = setInterval(async () => {
      try {
        const data = await apiService.getStats();
        setStats(data.conversation);
      } catch (error) {
        console.error('è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥:', error);
      }
    }, 5000);

    return () => clearInterval(interval);
  }, []);

  // å¤„ç†å¼€å§‹/åœæ­¢ç›‘å¬
  const handleToggleListening = async () => {
    if (!isListening) {
      // å¼€å§‹ç›‘å¬
      try {
        // æ£€æŸ¥æµè§ˆå™¨æ”¯æŒ
        if (!audioCaptureService.constructor.isSupported()) {
          setStatus('error');
          setStatusMessage('æµè§ˆå™¨ä¸æ”¯æŒéŸ³é¢‘é‡‡é›†');
          return;
        }

        // æ£€æŸ¥ WebSocket è¿æ¥
        if (!wsService.isConnected()) {
          setStatusMessage('æ­£åœ¨è¿æ¥æœåŠ¡å™¨...');
          await wsService.connect();
        }

        setStatus('listening');
        setStatusMessage('æ­£åœ¨å¯åŠ¨éŸ³é¢‘é‡‡é›†...');

        // é€šçŸ¥åç«¯å¼€å§‹ç›‘å¬
        wsService.send({ type: 'start_listening' });

        // å¼€å§‹éŸ³é¢‘é‡‡é›†
        await audioCaptureService.startCapture(audioSource, (audioData) => {
          // å‘é€éŸ³é¢‘æ•°æ®åˆ°åç«¯
          wsService.sendAudio(audioData);
        });

        setIsListening(true);
        setStatusMessage('æ­£åœ¨ç›‘å¬...');
        console.log('âœ… å¼€å§‹ç›‘å¬');
      } catch (error) {
        console.error('å¯åŠ¨ç›‘å¬å¤±è´¥:', error);
        setStatus('error');
        setStatusMessage(error instanceof Error ? error.message : 'å¯åŠ¨å¤±è´¥');
        setTimeout(() => setStatus('idle'), 3000);
      }
    } else {
      // åœæ­¢ç›‘å¬
      
      // é€šçŸ¥åç«¯åœæ­¢ç›‘å¬
      wsService.send({ type: 'stop_listening' });
      
      // åœæ­¢éŸ³é¢‘é‡‡é›†
      audioCaptureService.stopCapture();
      
      setIsListening(false);
      setStatus('idle');
      setStatusMessage('');
      console.log('âœ… åœæ­¢ç›‘å¬');
    }
  };

  // æ¸…ç©ºå¯¹è¯
  const handleClear = async () => {
    try {
      await apiService.clearConversation();
      setMessages([]);
      setStats({
        total_turns: 0,
        total_tokens: 0,
        l1_size: 0,
        l2_size: 0,
        l1_tokens: 0,
        l2_tokens: 0,
      });
      setStatusMessage('å†å²å·²æ¸…ç©º');
    } catch (error) {
      console.error('æ¸…ç©ºå¤±è´¥:', error);
      setStatus('error');
      setStatusMessage('æ¸…ç©ºå¤±è´¥');
    }
  };

  // åˆ‡æ¢éŸ³é¢‘æº
  const handleAudioSourceChange = (source: AudioSource) => {
    if (isListening) {
      setStatusMessage('è¯·å…ˆåœæ­¢ç›‘å¬');
      return;
    }
    setAudioSource(source);
    setStatusMessage(`å·²åˆ‡æ¢åˆ°: ${source === 'microphone' ? 'éº¦å…‹é£' : source === 'system' ? 'ç³»ç»ŸéŸ³é¢‘' : 'éº¦å…‹é£+ç³»ç»ŸéŸ³é¢‘'}`);
  };

  // æµ‹è¯•åŠŸèƒ½
  const handleTest = () => {
    const testMessages = [
      { role: 'teacher' as const, text: 'ä»Šå¤©æˆ‘ä»¬å­¦ä¹  Python çš„åŸºç¡€è¯­æ³•' },
      { role: 'student' as const, text: 'è€å¸ˆï¼Œä»€ä¹ˆæ˜¯å˜é‡ï¼Ÿ' },
      { role: 'system' as const, text: 'å˜é‡æ˜¯ç”¨æ¥å­˜å‚¨æ•°æ®çš„å®¹å™¨ã€‚åœ¨ Python ä¸­ï¼Œä½ å¯ä»¥ä½¿ç”¨ç­‰å·æ¥ç»™å˜é‡èµ‹å€¼ã€‚' },
    ];

    testMessages.forEach((msg, index) => {
      setTimeout(() => {
        wsService.sendText(msg.text, msg.role);
      }, index * 2000);
    });
  };

  return (
    <div className="min-h-screen bg-gradient-to-br from-gray-950 via-gray-900 to-gray-950">
      {/* èƒŒæ™¯è£…é¥° */}
      <div className="fixed inset-0 overflow-hidden pointer-events-none">
        <div className="absolute top-0 left-1/4 w-96 h-96 bg-primary-500/10 rounded-full blur-3xl" />
        <div className="absolute bottom-0 right-1/4 w-96 h-96 bg-accent-500/10 rounded-full blur-3xl" />
      </div>

      {/* ä¸»å†…å®¹ */}
      <div className="relative z-10 container mx-auto px-4 py-8">
        {/* å¤´éƒ¨ */}
        <motion.header
          initial={{ opacity: 0, y: -20 }}
          animate={{ opacity: 1, y: 0 }}
          className="mb-8"
        >
          <div className="flex items-center justify-between">
            <div className="flex items-center gap-4">
              <div className="w-12 h-12 bg-gradient-to-br from-primary-500 to-accent-500 rounded-xl flex items-center justify-center">
                <Mic className="w-6 h-6 text-white" />
              </div>
              <div>
                <h1 className="text-3xl font-bold gradient-text">
                  å®æ—¶è¯­éŸ³è¯†åˆ«ä¸æ™ºèƒ½å›å¤ç³»ç»Ÿ
                </h1>
                <p className="text-gray-400 text-sm mt-1">
                  AI é©±åŠ¨çš„åœ¨çº¿æˆè¯¾åŠ©æ‰‹
                </p>
              </div>
            </div>

            <div className="flex items-center gap-2">
              {isConnected ? (
                <>
                  <Wifi className="w-5 h-5 text-green-400" />
                  <span className="text-sm text-green-400">å·²è¿æ¥</span>
                </>
              ) : (
                <>
                  <WifiOff className="w-5 h-5 text-red-400" />
                  <span className="text-sm text-red-400">æœªè¿æ¥</span>
                </>
              )}
            </div>
          </div>
        </motion.header>

        {/* çŠ¶æ€æŒ‡ç¤ºå™¨ */}
        <StatusIndicator status={status} message={statusMessage} />

        {/* ä¸»è¦å†…å®¹åŒºåŸŸ */}
        <div className="grid grid-cols-1 lg:grid-cols-3 gap-6 mt-6">
          {/* å·¦ä¾§ - éŸ³é¢‘å¯è§†åŒ–å’Œå¯¹è¯ */}
          <div className="lg:col-span-2 space-y-6">
            <AudioVisualizer isActive={isListening} />
            <ConversationPanel messages={messages} />
          </div>

          {/* å³ä¾§ - æ§åˆ¶å’Œç»Ÿè®¡ */}
          <div className="space-y-6">
            <ControlPanel
              isListening={isListening}
              onToggleListening={handleToggleListening}
              onClear={handleClear}
            />

            {/* éŸ³é¢‘æºé€‰æ‹© */}
            <motion.div
              initial={{ opacity: 0, y: 20 }}
              animate={{ opacity: 1, y: 0 }}
              className="card p-4"
            >
              <h3 className="text-sm font-semibold text-gray-300 mb-3">éŸ³é¢‘æº</h3>
              <div className="space-y-2">
                <button
                  onClick={() => handleAudioSourceChange('microphone')}
                  disabled={isListening}
                  className={`w-full px-3 py-2 rounded-lg text-sm transition-colors ${
                    audioSource === 'microphone'
                      ? 'bg-primary-500 text-white'
                      : 'bg-gray-800 text-gray-300 hover:bg-gray-700'
                  } ${isListening ? 'opacity-50 cursor-not-allowed' : ''}`}
                >
                  ğŸ¤ éº¦å…‹é£
                </button>
                <button
                  onClick={() => handleAudioSourceChange('system')}
                  disabled={isListening}
                  className={`w-full px-3 py-2 rounded-lg text-sm transition-colors ${
                    audioSource === 'system'
                      ? 'bg-primary-500 text-white'
                      : 'bg-gray-800 text-gray-300 hover:bg-gray-700'
                  } ${isListening ? 'opacity-50 cursor-not-allowed' : ''}`}
                >
                  ğŸ”Š ç³»ç»ŸéŸ³é¢‘
                </button>
                <button
                  onClick={() => handleAudioSourceChange('both')}
                  disabled={isListening}
                  className={`w-full px-3 py-2 rounded-lg text-sm transition-colors ${
                    audioSource === 'both'
                      ? 'bg-primary-500 text-white'
                      : 'bg-gray-800 text-gray-300 hover:bg-gray-700'
                  } ${isListening ? 'opacity-50 cursor-not-allowed' : ''}`}
                >
                  ğŸ§ éº¦å…‹é£ + ç³»ç»ŸéŸ³é¢‘
                </button>
              </div>
            </motion.div>

            <StatsDisplay stats={stats} />

            {/* æµ‹è¯•æŒ‰é’® */}
            {process.env.NODE_ENV === 'development' && (
              <button
                onClick={handleTest}
                className="w-full btn-secondary text-sm"
              >
                ğŸ§ª æµ‹è¯•æ¨¡å¼
              </button>
            )}
          </div>
        </div>

        {/* é¡µè„š */}
        <motion.footer
          initial={{ opacity: 0 }}
          animate={{ opacity: 1 }}
          transition={{ delay: 0.5 }}
          className="mt-12 text-center text-gray-500 text-sm"
        >
          <p>Â© 2026 å®æ—¶è¯­éŸ³è¯†åˆ«ç³»ç»Ÿ Â· åŸºäºé˜¿é‡Œäº‘ DashScope å’Œé€šä¹‰åƒé—®</p>
        </motion.footer>
      </div>
    </div>
  );
}

export default App;

